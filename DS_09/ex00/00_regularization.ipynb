{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4           0           0            0   \n",
       "1     -0.756764 -2.562352          4           0           0            0   \n",
       "2     -0.724861 -2.562352          4           0           0            0   \n",
       "3     -0.692958 -2.562352          4           0           0            0   \n",
       "4     -0.661055 -2.562352          4           0           0            0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3           0           0            0   \n",
       "1682  -0.629151  0.945382          3           0           1            0   \n",
       "1683  -0.597248  0.945382          3           0           1            0   \n",
       "1684  -0.565345  0.945382          3           0           1            0   \n",
       "1685  -0.533442  0.945382          3           0           1            0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0               0            0            0            0  ...              0   \n",
       "1               0            0            0            0  ...              0   \n",
       "2               0            0            0            0  ...              0   \n",
       "3               0            0            0            0  ...              0   \n",
       "4               0            0            0            0  ...              0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681            0            0            0            0  ...              0   \n",
       "1682            0            0            0            0  ...              0   \n",
       "1683            0            0            0            0  ...              0   \n",
       "1684            0            0            0            0  ...              0   \n",
       "1685            0            0            0            0  ...              0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681              0               0               0               0   \n",
       "1682              0               0               0               0   \n",
       "1683              0               0               0               0   \n",
       "1684              0               0               0               0   \n",
       "1685              0               0               0               0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                   0               0               0                0   \n",
       "1                   0               0               0                0   \n",
       "2                   0               0               0                0   \n",
       "3                   0               0               0                0   \n",
       "4                   0               0               0                0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681                0               0               0                1   \n",
       "1682                0               0               0                1   \n",
       "1683                0               0               0                1   \n",
       "1684                0               0               0                1   \n",
       "1685                0               0               0                1   \n",
       "\n",
       "      labname_project1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1681                 0  \n",
       "1682                 0  \n",
       "1683                 0  \n",
       "1684                 0  \n",
       "1685                 0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dayofweek.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('dayofweek', axis=1)\n",
    "y = df.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(fit_intercept=False, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.62902   |   valid -  0.59259\n",
      "train -  0.64633   |   valid -  0.62963\n",
      "train -  0.63479   |   valid -  0.56296\n",
      "train -  0.65622   |   valid -  0.61481\n",
      "train -  0.63397   |   valid -  0.57778\n",
      "train -  0.64056   |   valid -  0.59259\n",
      "train -  0.64138   |   valid -  0.65926\n",
      "train -  0.65952   |   valid -  0.56296\n",
      "train -  0.64333   |   valid -  0.59701\n",
      "train -  0.63674   |   valid -  0.62687\n",
      "Average accuracy on crossval is 0.60165\n",
      "Std is 0.02943\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  logreg = logreg.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = logreg.predict(X_train.iloc[train_index])\n",
    "  y_tested = logreg.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.66529   |   valid -  0.62963\n",
      "train -  0.65705   |   valid -  0.65926\n",
      "train -  0.66447   |   valid -  0.57778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.66529   |   valid -  0.62963\n",
      "train -  0.66694   |   valid -  0.62222\n",
      "train -  0.65952   |   valid -  0.57778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.65045   |   valid -  0.69630\n",
      "train -  0.68673   |   valid -  0.61481\n",
      "train -  0.66474   |   valid -  0.62687\n",
      "train -  0.65651   |   valid -  0.61940\n",
      "Average accuracy on crossval is 0.62537\n",
      "Std is 0.03302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "logreg_none = LogisticRegression(fit_intercept=False, random_state=21, penalty='none')\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  logreg_none = logreg_none.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = logreg_none.predict(X_train.iloc[train_index])\n",
    "  y_tested = logreg_none.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.62902   |   valid -  0.59259\n",
      "train -  0.64633   |   valid -  0.62963\n",
      "train -  0.63479   |   valid -  0.56296\n",
      "train -  0.65622   |   valid -  0.61481\n",
      "train -  0.63397   |   valid -  0.57778\n",
      "train -  0.64056   |   valid -  0.59259\n",
      "train -  0.64138   |   valid -  0.65926\n",
      "train -  0.65952   |   valid -  0.56296\n",
      "train -  0.64333   |   valid -  0.59701\n",
      "train -  0.63674   |   valid -  0.62687\n",
      "Average accuracy on crossval is 0.60165\n",
      "Std is 0.02943\n"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(fit_intercept=False, random_state=21, penalty='l2')\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  logreg2 = logreg2.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = logreg2.predict(X_train.iloc[train_index])\n",
    "  y_tested = logreg2.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zz/zyxvpxvq6csfxvn_n003vrph00yy5m/T/ipykernel_90403/3429919897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccuracy_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mlogreg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0my_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0my_tested\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \"\"\"\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/goinfre/einterdi/Piscine_Python_Data_Science/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m    447\u001b[0m         raise ValueError(\n\u001b[1;32m    448\u001b[0m             \u001b[0;34m\"Solver %s supports only 'l2' or 'none' penalties, got %s penalty.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"liblinear\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(fit_intercept=False, random_state=21, penalty='l1')\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  logreg1 = logreg1.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = logreg1.predict(X_train.iloc[train_index])\n",
    "  y_tested = logreg1.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.59192   |   valid -  0.57037\n",
      "train -  0.58945   |   valid -  0.57037\n",
      "train -  0.57955   |   valid -  0.49630\n",
      "train -  0.61418   |   valid -  0.60741\n",
      "train -  0.58945   |   valid -  0.52593\n",
      "train -  0.58450   |   valid -  0.56296\n",
      "train -  0.58945   |   valid -  0.62963\n",
      "train -  0.61995   |   valid -  0.55556\n",
      "train -  0.61367   |   valid -  0.58955\n",
      "train -  0.61779   |   valid -  0.59701\n",
      "Average accuracy on crossval is 0.57051\n",
      "Std is 0.03701\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=21))\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  clf.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = clf.predict(X_train.iloc[train_index])\n",
    "  y_tested = clf.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.60181   |   valid -  0.57778\n",
      "train -  0.60429   |   valid -  0.60000\n",
      "train -  0.58450   |   valid -  0.50370\n",
      "train -  0.60923   |   valid -  0.61481\n",
      "train -  0.58615   |   valid -  0.53333\n",
      "train -  0.59439   |   valid -  0.54815\n",
      "train -  0.58697   |   valid -  0.62963\n",
      "train -  0.61913   |   valid -  0.57037\n",
      "train -  0.61532   |   valid -  0.59701\n",
      "train -  0.60791   |   valid -  0.59701\n",
      "Average accuracy on crossval is 0.57718\n",
      "Std is 0.03699\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=21, C=4))\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  clf.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = clf.predict(X_train.iloc[train_index])\n",
    "  y_tested = clf.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.58862   |   valid -  0.58519\n",
      "train -  0.60758   |   valid -  0.60000\n",
      "train -  0.58368   |   valid -  0.46667\n",
      "train -  0.61500   |   valid -  0.59259\n",
      "train -  0.58862   |   valid -  0.56296\n",
      "train -  0.60841   |   valid -  0.55556\n",
      "train -  0.58285   |   valid -  0.62963\n",
      "train -  0.60758   |   valid -  0.55556\n",
      "train -  0.62026   |   valid -  0.59701\n",
      "train -  0.58814   |   valid -  0.56716\n",
      "Average accuracy on crossval is 0.57123\n",
      "Std is 0.04131\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=21, C=40))\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  clf.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = clf.predict(X_train.iloc[train_index])\n",
    "  y_tested = clf.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.60429   |   valid -  0.58519\n",
      "train -  0.58780   |   valid -  0.57037\n",
      "train -  0.60264   |   valid -  0.51111\n",
      "train -  0.58368   |   valid -  0.60000\n",
      "train -  0.60511   |   valid -  0.56296\n",
      "train -  0.63397   |   valid -  0.56296\n",
      "train -  0.59439   |   valid -  0.63704\n",
      "train -  0.59439   |   valid -  0.57778\n",
      "train -  0.62356   |   valid -  0.61194\n",
      "train -  0.60214   |   valid -  0.57463\n",
      "Average accuracy on crossval is 0.57940\n",
      "Std is 0.03186\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=21, C=100))\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  clf.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = clf.predict(X_train.iloc[train_index])\n",
    "  y_tested = clf.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  1.00000   |   valid -  0.85926\n",
      "train -  1.00000   |   valid -  0.91852\n",
      "train -  0.99918   |   valid -  0.86667\n",
      "train -  1.00000   |   valid -  0.91111\n",
      "train -  0.99918   |   valid -  0.88889\n",
      "train -  0.99835   |   valid -  0.85185\n",
      "train -  1.00000   |   valid -  0.92593\n",
      "train -  1.00000   |   valid -  0.88148\n",
      "train -  1.00000   |   valid -  0.88060\n",
      "train -  1.00000   |   valid -  0.88060\n",
      "Average accuracy on crossval is 0.88649\n",
      "Std is 0.02371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 25}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'max_depth': [1, 5, 10, 15, 25, 30]\n",
    "}\n",
    "tD = tree.DecisionTreeClassifier(random_state=21)\n",
    "clf = GridSearchCV(tD, parameters)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  clf.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = clf.predict(X_train.iloc[train_index])\n",
    "  y_tested = clf.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  1.00000   |   valid -  0.90370\n",
      "train -  1.00000   |   valid -  0.95556\n",
      "train -  0.99918   |   valid -  0.89630\n",
      "train -  1.00000   |   valid -  0.93333\n",
      "train -  0.99835   |   valid -  0.92593\n",
      "train -  0.99918   |   valid -  0.89630\n",
      "train -  1.00000   |   valid -  0.92593\n",
      "train -  1.00000   |   valid -  0.90370\n",
      "train -  1.00000   |   valid -  0.92537\n",
      "train -  0.99918   |   valid -  0.88806\n",
      "Average accuracy on crossval is 0.91542\n",
      "Std is 0.02002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'n_estimators': 50}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('dayofweek', axis=1)\n",
    "y = df.dayofweek\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [10, 50, 100, 150],\n",
    "    'max_depth': [1, 5, 10, 14, 25, 30]\n",
    "}\n",
    "random_forest_model = RandomForestClassifier(random_state=21)\n",
    "clf = GridSearchCV(random_forest_model, parameters, scoring='accuracy', n_jobs=-1)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy_valid = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "  clf.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "  y_trained = clf.predict(X_train.iloc[train_index])\n",
    "  y_tested = clf.predict(X_train.iloc[test_index])\n",
    "  accuracy_score_train = accuracy_score(y_train.iloc[train_index], y_trained)\n",
    "  accuracy_score_test = accuracy_score(y_train.iloc[test_index], y_tested)\n",
    "  accuracy_valid.append(accuracy_score_test)\n",
    "  print(f'train -  {accuracy_score_train:0.5f}   |   valid -  {accuracy_score_test:0.5f}')\n",
    "print(f'Average accuracy on crossval is {np.array(accuracy_valid).mean():0.5f}')\n",
    "print(f'Std is {np.array(accuracy_valid).std():0.5f}')\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, the best results come from random forest model<br>\n",
    "Parameters: n_estimators=50, max_depth=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289940828402367"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state=21, n_estimators=50, max_depth=30)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "y_after_test = random_forest_model.predict(X_test)\n",
    "accuracy_score(y_test, y_after_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 6, 3, 2, 1, 5, 5, 6, 6, 5, 6, 3, 0, 3, 3, 5, 3, 3, 6, 3, 4,\n",
       "       3, 3, 6, 1, 5, 3, 1, 6, 6, 5, 6, 6, 3, 5, 6, 0, 1, 6, 6, 5, 5, 1,\n",
       "       6, 1, 6, 3, 2, 1, 1, 5, 5, 4, 6, 6, 1, 6, 0, 3, 1, 3, 1, 1, 4, 4,\n",
       "       2, 0, 3, 6, 5, 6, 5, 2, 5, 5, 4, 0, 5, 6, 1, 0, 1, 3, 6, 5, 5, 6,\n",
       "       5, 3, 6, 3, 4, 1, 3, 6, 3, 6, 4, 3, 3, 0, 2, 1, 6, 0, 0, 4, 3, 3,\n",
       "       4, 1, 5, 0, 6, 5, 5, 1, 5, 3, 6, 3, 3, 0, 0, 6, 4, 6, 5, 6, 3, 5,\n",
       "       6, 3, 2, 6, 5, 6, 5, 4, 6, 1, 6, 6, 5, 3, 1, 1, 3, 1, 1, 3, 1, 0,\n",
       "       3, 3, 5, 6, 2, 5, 0, 6, 2, 3, 5, 3, 3, 0, 3, 3, 3, 6, 3, 5, 0, 3,\n",
       "       5, 3, 3, 5, 3, 1, 5, 2, 3, 0, 3, 1, 2, 3, 0, 2, 6, 6, 5, 5, 2, 2,\n",
       "       1, 6, 6, 5, 5, 6, 3, 6, 2, 5, 2, 6, 1, 3, 1, 5, 4, 4, 1, 3, 5, 3,\n",
       "       2, 5, 1, 0, 3, 3, 1, 3, 1, 6, 6, 6, 6, 4, 6, 2, 1, 4, 6, 0, 1, 3,\n",
       "       5, 6, 6, 3, 5, 2, 5, 6, 3, 2, 3, 4, 5, 6, 3, 6, 3, 1, 1, 3, 1, 5,\n",
       "       6, 6, 6, 4, 3, 3, 2, 3, 6, 3, 1, 6, 1, 3, 3, 3, 5, 3, 0, 3, 2, 6,\n",
       "       2, 6, 6, 1, 5, 4, 3, 6, 0, 3, 6, 1, 3, 2, 6, 6, 6, 5, 2, 1, 6, 4,\n",
       "       1, 3, 0, 5, 6, 4, 1, 3, 3, 3, 3, 2, 5, 3, 1, 5, 1, 2, 3, 5, 3, 3,\n",
       "       6, 3, 5, 3, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_after_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0029585798816568047 0 1\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 4 4\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0029585798816568047 6 5\n",
      "0.0 6 6\n",
      "0.0029585798816568047 5 4\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.026627218934911243 0 3\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 5 5\n",
      "0.0 1 1\n",
      "0.10650887573964497 6 0\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 1 1\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 5 5\n",
      "0.0 4 4\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 1 1\n",
      "0.047337278106508875 4 0\n",
      "0.0 4 4\n",
      "0.0 2 2\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 2 2\n",
      "0.0 5 5\n",
      "0.0 5 5\n",
      "0.0 4 4\n",
      "0.0 0 0\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0029585798816568047 0 1\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.047337278106508875 5 1\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 4 4\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 4 4\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 0 0\n",
      "0.0 2 2\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 0 0\n",
      "0.0 0 0\n",
      "0.0 4 4\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0029585798816568047 4 5\n",
      "0.0 1 1\n",
      "0.011834319526627219 5 3\n",
      "0.0 0 0\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 5 5\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 0 0\n",
      "0.0 0 0\n",
      "0.0 6 6\n",
      "0.0 4 4\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 6 6\n",
      "0.0029585798816568047 5 4\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 4 4\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 2 2\n",
      "0.0 5 5\n",
      "0.0 0 0\n",
      "0.0 6 6\n",
      "0.0 2 2\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0029585798816568047 3 2\n",
      "0.0 3 3\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.011834319526627219 3 5\n",
      "0.0 5 5\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 2 2\n",
      "0.0 3 3\n",
      "0.0 0 0\n",
      "0.0029585798816568047 3 2\n",
      "0.0 1 1\n",
      "0.0 2 2\n",
      "0.0 3 3\n",
      "0.0 0 0\n",
      "0.0 2 2\n",
      "0.10650887573964497 6 0\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 5 5\n",
      "0.0 2 2\n",
      "0.0 2 2\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 5 5\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 2 2\n",
      "0.0 5 5\n",
      "0.0 2 2\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 4 4\n",
      "0.0 4 4\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 5 5\n",
      "0.0 1 1\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.011834319526627219 3 1\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.10650887573964497 6 0\n",
      "0.0 6 6\n",
      "0.0 4 4\n",
      "0.0 6 6\n",
      "0.0 2 2\n",
      "0.0 1 1\n",
      "0.0 4 4\n",
      "0.0 6 6\n",
      "0.0 0 0\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 2 2\n",
      "0.07396449704142012 5 0\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 3 3\n",
      "0.0 4 4\n",
      "0.0 5 5\n",
      "0.10650887573964497 6 0\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.026627218934911243 3 0\n",
      "0.0 1 1\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 4 4\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.011834319526627219 3 5\n",
      "0.0029585798816568047 5 6\n",
      "0.011834319526627219 3 1\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 6 6\n",
      "0.0 2 2\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 4 4\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 0 0\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0 6 6\n",
      "0.0029585798816568047 5 4\n",
      "0.0 2 2\n",
      "0.0 1 1\n",
      "0.0 6 6\n",
      "0.0 4 4\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 0 0\n",
      "0.0 5 5\n",
      "0.0 6 6\n",
      "0.0 4 4\n",
      "0.0 1 1\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 2 2\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 5 5\n",
      "0.0 1 1\n",
      "0.0 2 2\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 3 3\n",
      "0.0 6 6\n",
      "0.0 3 3\n",
      "0.0 5 5\n",
      "0.0 3 3\n",
      "0.0 1 1\n",
      "0.0 2 2\n",
      "0.0 1 1\n",
      "0.0 2 2\n",
      "max error: 0.10650887573964497\n",
      "Max err is for 0 day\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# error = []\n",
    "# for i in range(len(list(y_test))):\n",
    "#     err = (y_after_test[i] - list(y_test)[i]) ** 2\n",
    "#     err_param = err / len(list(y_test))\n",
    "#     error.append(err_param)\n",
    "#     print(err_param, y_after_test[i], list(y_test)[i])\n",
    "# max_error = max(error)\n",
    "# print(f'max error: {max_error}')\n",
    "# for i in range(len(list(y_test))):\n",
    "#     err = (y_after_test[i] - list(y_test)[i]) ** 2\n",
    "#     err_param = err / len(list(y_test))\n",
    "#     if err_param == max_error:\n",
    "#         print(f'Max err is for {list(y_test)[i]} day')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_after_test, labels=random_forest_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=random_forest_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'model_random_tree.sav'\n",
    "pickle.dump(random_forest_model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "084c2177a1bafd335d0d21cc69b2e2a4dfa0e714de70b55da0b3d79e8ec53de4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
